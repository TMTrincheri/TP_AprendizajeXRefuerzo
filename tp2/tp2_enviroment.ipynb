{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install stable_baselines3\n",
    "%pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gymnasium[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\pbonafe\\diplo\\rl\\virtualenv\\venv\\lib\\site-packages (from opencv-python) (1.26.1)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.1.78\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stable_baselines3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pbonafe\\Diplo\\RL\\TP_AprendizajeXRefuerzo\\tp2_enviroment.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pbonafe/Diplo/RL/TP_AprendizajeXRefuerzo/tp2_enviroment.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstable_baselines3\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pbonafe/Diplo/RL/TP_AprendizajeXRefuerzo/tp2_enviroment.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'stable_baselines3'"
     ]
    }
   ],
   "source": [
    "import stable_baselines3\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard module is not an IPython extension.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from subprocess import Popen, PIPE\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from snakeenv import SnakeEnv\n",
    "\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pbonafe\\Diplo\\RL\\TP_AprendizajeXRefuerzo\\tp2_enviroment.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pbonafe/Diplo/RL/TP_AprendizajeXRefuerzo/tp2_enviroment.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# MlpPolicy es una política \"estándar\" que aprende con perceptron multicapa\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pbonafe/Diplo/RL/TP_AprendizajeXRefuerzo/tp2_enviroment.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# (es decir sin capas convolucionales o demás variantes),\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pbonafe/Diplo/RL/TP_AprendizajeXRefuerzo/tp2_enviroment.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# 2 capas ocultas con 64 neuronas cada una\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pbonafe/Diplo/RL/TP_AprendizajeXRefuerzo/tp2_enviroment.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m DQN(\u001b[39m\"\u001b[39m\u001b[39mMlpPolicy\u001b[39m\u001b[39m\"\u001b[39m, env)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pbonafe/Diplo/RL/TP_AprendizajeXRefuerzo/tp2_enviroment.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\pbonafe\\Diplo\\RL\\virtualenv\\venv\\Lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:267\u001b[0m, in \u001b[0;36mDQN.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    259\u001b[0m     \u001b[39mself\u001b[39m: SelfDQN,\n\u001b[0;32m    260\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    266\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfDQN:\n\u001b[1;32m--> 267\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    268\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    269\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    270\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    271\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    272\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    273\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m    274\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pbonafe\\Diplo\\RL\\virtualenv\\venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:301\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    293\u001b[0m     \u001b[39mself\u001b[39m: SelfOffPolicyAlgorithm,\n\u001b[0;32m    294\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    299\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    300\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfOffPolicyAlgorithm:\n\u001b[1;32m--> 301\u001b[0m     total_timesteps, callback \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_learn(\n\u001b[0;32m    302\u001b[0m         total_timesteps,\n\u001b[0;32m    303\u001b[0m         callback,\n\u001b[0;32m    304\u001b[0m         reset_num_timesteps,\n\u001b[0;32m    305\u001b[0m         tb_log_name,\n\u001b[0;32m    306\u001b[0m         progress_bar,\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    309\u001b[0m     callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[0;32m    311\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n",
      "File \u001b[1;32mc:\\Users\\pbonafe\\Diplo\\RL\\virtualenv\\venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:284\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    281\u001b[0m     pos \u001b[39m=\u001b[39m (replay_buffer\u001b[39m.\u001b[39mpos \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m replay_buffer\u001b[39m.\u001b[39mbuffer_size\n\u001b[0;32m    282\u001b[0m     replay_buffer\u001b[39m.\u001b[39mdones[pos] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_setup_learn(\n\u001b[0;32m    285\u001b[0m     total_timesteps,\n\u001b[0;32m    286\u001b[0m     callback,\n\u001b[0;32m    287\u001b[0m     reset_num_timesteps,\n\u001b[0;32m    288\u001b[0m     tb_log_name,\n\u001b[0;32m    289\u001b[0m     progress_bar,\n\u001b[0;32m    290\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\pbonafe\\Diplo\\RL\\virtualenv\\venv\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:424\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[39m# pytype: disable=annotation-type-mismatch\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mreset()  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[39m# pytype: enable=annotation-type-mismatch\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_episode_starts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mnum_envs,), dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pbonafe\\Diplo\\RL\\virtualenv\\venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:76\u001b[0m, in \u001b[0;36mDummyVecEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvObs:\n\u001b[0;32m     75\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[1;32m---> 76\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menvs[env_idx]\u001b[39m.\u001b[39mreset(seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_seeds[env_idx])\n\u001b[0;32m     77\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     78\u001b[0m     \u001b[39m# Seeds are only used once\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#import gym \n",
    "\n",
    "env = SnakeEnv()\n",
    "\n",
    "# MlpPolicy es una política \"estándar\" que aprende con perceptron multicapa\n",
    "# (es decir sin capas convolucionales o demás variantes),\n",
    "# 2 capas ocultas con 64 neuronas cada una\n",
    "model = DQN(\"MlpPolicy\", env)\n",
    "model.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
